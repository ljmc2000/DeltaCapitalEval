# Setting it up

`docker-compose up --build`

# Usage

The API has 2 defined endpoints. The first is /api/execute_flow. This will execute a flow based on the JSON provided and return a run_id and a link to the log. The flow will execute in the background. The second is the /run endpoint. This statically serves any files generated by execute_flow including log files.

/api/execute_flow is a POST endpoint. Here is the expected shape of the data. It is largely based on the sample provided.

```
{
	flow: {
		id: string -- an identifier for the flow, unused but not optional
		name: string -- a name for the flow. Again unused but not optional
		start_task: string -- the first task to execute. The root task which other tasks depend on
		initial_value: any -- arguments for the first task. This is my first deviation from the provided model
		tasks: Task[] -- A list of Task objects, see below
		conditions: Condition[] -- A list of Condition objects, see below
	} -- a flow
} -- an outer container for flow, like the sample provided

Task {
	name: string -- the tasks name. Turns up in log files
	description: string -- the task's description. currently unused but not optional
	handler: string -- a reference to a function. I thought about going by task name but calling everything task1 and task3 was ruining readability. The other deviation from the base model
}

Condition {
	name: string -- the name of the condition. Not used but not optional
	description: string -- Not yet used but not optional
	source_task: string -- The name of a task. Will error if not listed in the tasks above
	outcome: string -- I'll be honest, I have no idea what this was intended to represent. Unused, not optional.
	target_task_success: string -- the name of the task that should execute if source_task was successful
	target_task_failure: string -- the name of the task that should execute if source_task was not successful.
}
```

# Example command for curl

`curl -H 'Content-Type: application/json' -d @sample_request.json localhost:8000/api/execute_flow`

# Explanation of flow design

I tried my best to stick to the model of the JSON provided, so my algorithm is thus. 

1. Compile a list of tasks indexed by name
2. Examine the relationships between the tasks
	- If a task should run on success of another task add it to that task's on-success list
	- If a task should run on failure of another task add it to that task's on-failure list
3. Execute the first task
4. If successful sequentially execute every task on the first task's on-success list. Otherwise sequentially execute every task on the first task's on-failure list
5. Repeat recursively until you run out of tasks. If the same task is encountered twice, skip it and its lists of dependencies. This is to prevent a fork bomb

![Demonstration of order](order-demo.gif)